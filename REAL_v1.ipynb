{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:14:16.632771Z","iopub.status.busy":"2023-11-03T07:14:16.632075Z","iopub.status.idle":"2023-11-03T07:14:39.131486Z","shell.execute_reply":"2023-11-03T07:14:39.130567Z","shell.execute_reply.started":"2023-11-03T07:14:16.632734Z"},"trusted":true},"outputs":[],"source":["# Import necessary libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import re\n","from nltk.corpus import stopwords\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset, random_split\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:14:39.133694Z","iopub.status.busy":"2023-11-03T07:14:39.133375Z","iopub.status.idle":"2023-11-03T07:14:39.243035Z","shell.execute_reply":"2023-11-03T07:14:39.242196Z","shell.execute_reply.started":"2023-11-03T07:14:39.133666Z"},"trusted":true},"outputs":[],"source":["train_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/train_essays.csv\")\n","test_essays = pd.read_csv(\"/kaggle/input/llm-detect-ai-generated-text/test_essays.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:14:39.24461Z","iopub.status.busy":"2023-11-03T07:14:39.244294Z","iopub.status.idle":"2023-11-03T07:14:39.289996Z","shell.execute_reply":"2023-11-03T07:14:39.28905Z","shell.execute_reply.started":"2023-11-03T07:14:39.244583Z"},"trusted":true},"outputs":[],"source":["# Explore the training data\n","train_essays.info()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:14:39.291662Z","iopub.status.busy":"2023-11-03T07:14:39.291379Z","iopub.status.idle":"2023-11-03T07:14:39.30842Z","shell.execute_reply":"2023-11-03T07:14:39.307524Z","shell.execute_reply.started":"2023-11-03T07:14:39.291637Z"},"trusted":true},"outputs":[],"source":["train_essays.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:14:39.311614Z","iopub.status.busy":"2023-11-03T07:14:39.311303Z","iopub.status.idle":"2023-11-03T07:14:39.582052Z","shell.execute_reply":"2023-11-03T07:14:39.580949Z","shell.execute_reply.started":"2023-11-03T07:14:39.311589Z"},"trusted":true},"outputs":[],"source":["# Check for class balance\n","sns.countplot(data=train_essays, x='generated')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:14:39.583606Z","iopub.status.busy":"2023-11-03T07:14:39.58329Z","iopub.status.idle":"2023-11-03T07:14:40.083101Z","shell.execute_reply":"2023-11-03T07:14:40.082044Z","shell.execute_reply.started":"2023-11-03T07:14:39.583577Z"},"trusted":true},"outputs":[],"source":["# Text Preprocessing\n","stop_words = set(stopwords.words('english'))\n","\n","def clean_text(text):\n","    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuations\n","    words = text.split()  # Tokenize\n","    words = [word.lower() for word in words if word.isalpha()]  # Lowercase and remove non-alphabetic words\n","    words = [word for word in words if word not in stop_words]  # Remove stop words\n","    return ' '.join(words)\n","\n","train_essays['clean_text'] = train_essays['text'].apply(clean_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:14:40.085405Z","iopub.status.busy":"2023-11-03T07:14:40.084977Z","iopub.status.idle":"2023-11-03T07:14:40.092651Z","shell.execute_reply":"2023-11-03T07:14:40.0916Z","shell.execute_reply.started":"2023-11-03T07:14:40.085371Z"},"trusted":true},"outputs":[],"source":["# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val = train_test_split(train_essays['clean_text'], train_essays['generated'], test_size=0.2, random_state=42)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:14:40.094139Z","iopub.status.busy":"2023-11-03T07:14:40.093831Z","iopub.status.idle":"2023-11-03T07:14:40.917295Z","shell.execute_reply":"2023-11-03T07:14:40.916492Z","shell.execute_reply.started":"2023-11-03T07:14:40.094112Z"},"trusted":true},"outputs":[],"source":["# Tokenization and Encoding for BERT\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True, padding=True, truncation=True, max_length=128)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:14:40.918948Z","iopub.status.busy":"2023-11-03T07:14:40.91867Z","iopub.status.idle":"2023-11-03T07:15:00.58084Z","shell.execute_reply":"2023-11-03T07:15:00.579879Z","shell.execute_reply.started":"2023-11-03T07:14:40.918923Z"},"trusted":true},"outputs":[],"source":["encoded_train = tokenizer(X_train.tolist(), padding=True, truncation=True, return_tensors='pt')\n","encoded_val = tokenizer(X_val.tolist(), padding=True, truncation=True, return_tensors='pt')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:15:00.582315Z","iopub.status.busy":"2023-11-03T07:15:00.582009Z","iopub.status.idle":"2023-11-03T07:15:00.608951Z","shell.execute_reply":"2023-11-03T07:15:00.607971Z","shell.execute_reply.started":"2023-11-03T07:15:00.582288Z"},"trusted":true},"outputs":[],"source":["# Convert labels to tensors\n","train_labels = torch.tensor(y_train.values)\n","val_labels = torch.tensor(y_val.values)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:15:00.611121Z","iopub.status.busy":"2023-11-03T07:15:00.610743Z","iopub.status.idle":"2023-11-03T07:15:00.61616Z","shell.execute_reply":"2023-11-03T07:15:00.615127Z","shell.execute_reply.started":"2023-11-03T07:15:00.611087Z"},"trusted":true},"outputs":[],"source":["# Create TensorDatasets\n","train_dataset = TensorDataset(encoded_train['input_ids'], encoded_train['attention_mask'], train_labels)\n","val_dataset = TensorDataset(encoded_val['input_ids'], encoded_val['attention_mask'], val_labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:15:00.617724Z","iopub.status.busy":"2023-11-03T07:15:00.617431Z","iopub.status.idle":"2023-11-03T07:15:00.629784Z","shell.execute_reply":"2023-11-03T07:15:00.628994Z","shell.execute_reply.started":"2023-11-03T07:15:00.617692Z"},"trusted":true},"outputs":[],"source":["# DataLoader for efficient processing\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:15:00.631235Z","iopub.status.busy":"2023-11-03T07:15:00.630906Z","iopub.status.idle":"2023-11-03T07:15:12.290208Z","shell.execute_reply":"2023-11-03T07:15:12.28924Z","shell.execute_reply.started":"2023-11-03T07:15:00.6312Z"},"trusted":true},"outputs":[],"source":["# Define the BERT model for sequence classification\n","model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:15:12.293719Z","iopub.status.busy":"2023-11-03T07:15:12.293406Z","iopub.status.idle":"2023-11-03T07:15:12.304608Z","shell.execute_reply":"2023-11-03T07:15:12.303595Z","shell.execute_reply.started":"2023-11-03T07:15:12.293692Z"},"trusted":true},"outputs":[],"source":["# Define optimizer and learning rate scheduler\n","optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n","epochs = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:15:12.306352Z","iopub.status.busy":"2023-11-03T07:15:12.305694Z","iopub.status.idle":"2023-11-03T07:31:37.582938Z","shell.execute_reply":"2023-11-03T07:31:37.581668Z","shell.execute_reply.started":"2023-11-03T07:15:12.306314Z"},"trusted":true},"outputs":[],"source":["# Training loop\n","for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    for batch in train_loader:\n","        input_ids, attention_mask, labels = batch\n","        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n","        loss = outputs.loss\n","        total_loss += loss.item()\n","\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping to avoid exploding gradients\n","        optimizer.step()\n","\n","    avg_train_loss = total_loss / len(train_loader)\n","    print(f\"Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss:.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:31:37.584615Z","iopub.status.busy":"2023-11-03T07:31:37.584295Z","iopub.status.idle":"2023-11-03T07:31:46.483805Z","shell.execute_reply":"2023-11-03T07:31:46.482678Z","shell.execute_reply.started":"2023-11-03T07:31:37.584587Z"},"trusted":true},"outputs":[],"source":["# Validation loop\n","model.eval()\n","val_preds = []\n","val_labels = []\n","\n","with torch.no_grad():\n","    for batch in val_loader:\n","        input_ids, attention_mask, labels = batch\n","        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n","\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        logits = outputs.logits\n","\n","        val_preds.extend(torch.argmax(logits, dim=1).cpu().numpy())\n","        val_labels.extend(labels.cpu().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:31:46.487025Z","iopub.status.busy":"2023-11-03T07:31:46.486072Z","iopub.status.idle":"2023-11-03T07:31:46.493984Z","shell.execute_reply":"2023-11-03T07:31:46.492879Z","shell.execute_reply.started":"2023-11-03T07:31:46.486983Z"},"trusted":true},"outputs":[],"source":["# Calculate validation accuracy\n","val_accuracy = accuracy_score(val_labels, val_preds)\n","print(f\"Validation Accuracy: {val_accuracy:.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T07:31:46.495561Z","iopub.status.busy":"2023-11-03T07:31:46.495176Z","iopub.status.idle":"2023-11-03T07:31:46.545354Z","shell.execute_reply":"2023-11-03T07:31:46.544334Z","shell.execute_reply.started":"2023-11-03T07:31:46.495523Z"},"trusted":true},"outputs":[],"source":["# Test data processing\n","test_inputs = tokenizer(test_essays['text'].tolist(), padding=True, truncation=True, return_tensors='pt')\n","\n","# Move input tensor to the same device as the model\n","test_inputs = {key: value.to(device) for key, value in test_inputs.items()}\n","\n","# Generate predictions using your trained model\n","with torch.no_grad():\n","    outputs = model(**test_inputs)\n","    logits = outputs.logits\n","\n","# Assuming the first column of logits corresponds to the negative class (non-AI-generated) \n","# and the second column corresponds to the positive class (AI-generated)\n","predictions = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()  # Move predictions back to CPU\n","\n","# Create a submission DataFrame with essay IDs and corresponding predictions\n","result = pd.DataFrame({\n","    'id': test_essays['id'],\n","    'generated': predictions\n","})\n","\n","# Save the submission DataFrame to a CSV file\n","result.to_csv('/kaggle/working/submission.csv', index=False)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
